{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xZyTIqdZLG"
      },
      "source": [
        "**Download this dataset from Kaggle first: marklvl/sentiment-labelled-sentences-data-set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo8pYo-0dZLI",
        "outputId": "54e2cd8f-29d3-43c3-cb90-b29dd4058aee"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "TqEqTbKqelJG",
        "outputId": "c5e16d89-b325-477d-ead3-8de534ed320e"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ac1a76c8-beba-4fee-a752-d9ff9d3b04b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ac1a76c8-beba-4fee-a752-d9ff9d3b04b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ahsantarique\",\"key\":\"f10a12d8f5ffa3359d88d97311a12d2b\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr2qQxN1er92"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-GnNPckeab5",
        "outputId": "610b1bb0-d882-4bee-e71c-f016c6ecbd74"
      },
      "source": [
        "!kaggle datasets download marklvl/sentiment-labelled-sentences-data-set\r\n",
        "!unzip sentiment-labelled-sentences-data-set.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment-labelled-sentences-data-set.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  sentiment-labelled-sentences-data-set.zip\n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/readme.txt  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.csv  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BxtyUMQe_I5",
        "outputId": "385d8d8f-227d-4e3b-f1f1-4d83b71f6575"
      },
      "source": [
        "!ls 'sentiment labelled sentences'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " amazon_cells_labelled.csv   imdb_labelled.txt\t\t     yelp_labelled.csv\n",
            " amazon_cells_labelled.txt   readme.txt\t\t\t     yelp_labelled.txt\n",
            " imdb_labelled.csv\t    'sentiment labelled sentences'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXjdL1q6dZLK"
      },
      "source": [
        "**Now let's sample some sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX59VIh1dZLL"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "V3gkOHocdZLL",
        "outputId": "ac92db5c-2607-4d80-df5b-e5a6ac920f46"
      },
      "source": [
        "amazon_df=pd.read_csv(\"sentiment labelled sentences/amazon_cells_labelled.txt\",delimiter='\\t',\n",
        "                        header=None, \n",
        "                        names=['sentence', 'sentiment'])\n",
        "\n",
        "imdb_df = pd.read_csv(\"sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt\", \n",
        "                        delimiter='\\t', \n",
        "                        header=None, \n",
        "                        names=['sentence', 'sentiment'])\n",
        "\n",
        "yelp_df = pd.read_csv(\"sentiment labelled sentences/yelp_labelled.txt\", \n",
        "                        delimiter='\\t', \n",
        "                        header=None, \n",
        "                        names=['sentence', 'sentiment'])\n",
        "\n",
        "amazon_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment\n",
              "0  So there is no way for me to plug it in here i...          0\n",
              "1                        Good case, Excellent value.          1\n",
              "2                             Great for the jawbone.          1\n",
              "3  Tied to charger for conversations lasting more...          0\n",
              "4                                  The mic is great.          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "uG1XJFZZdZLM",
        "outputId": "f192288f-e49e-4b10-dbb9-2a046b3a0ad3"
      },
      "source": [
        "data = pd.concat([amazon_df,yelp_df,imdb_df])\r\n",
        "\r\n",
        "TEST_SIZE = 20  ## change the test size as needed\r\n",
        "test_set = data.sample(n = TEST_SIZE, random_state = 1, replace = False)\r\n",
        "test_set.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>This is a really fantastic Thai restaurant whi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>The RI style calamari was a joke.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>Please stay away from the shrimp stir fried no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>Anyway, this FS restaurant has a wonderful bre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>IT'S REALLY EASY.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  sentiment\n",
              "112  This is a really fantastic Thai restaurant whi...          1\n",
              "923                  The RI style calamari was a joke.          0\n",
              "301  Please stay away from the shrimp stir fried no...          0\n",
              "442  Anyway, this FS restaurant has a wonderful bre...          1\n",
              "428                                  IT'S REALLY EASY.          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re0AmSgpfjwD"
      },
      "source": [
        "**Task 1.1:: Now let's classify using Vader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ung_zInafpF3",
        "outputId": "73417e9b-297b-42c9-8f2f-10ea29524231"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
        "import nltk\r\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAoyFiDRfsrZ",
        "outputId": "dc3c1c53-0ea5-40ef-d037-c700a35b0517"
      },
      "source": [
        "model = SentimentIntensityAnalyzer()\r\n",
        "for sentence in test_set['sentence']:\r\n",
        "    sentiment = model.polarity_scores(sentence)\r\n",
        "    print('Sentence: ', sentence)\r\n",
        "    print('Sentiment:', sentiment, end='\\n\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:  This is a really fantastic Thai restaurant which is definitely worth a visit.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.485, 'pos': 0.515, 'compound': 0.8173}\n",
            "\n",
            "Sentence:  The RI style calamari was a joke.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'compound': 0.296}\n",
            "\n",
            "Sentence:  Please stay away from the shrimp stir fried noodles.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.777, 'pos': 0.223, 'compound': 0.3182}\n",
            "\n",
            "Sentence:  Anyway, this FS restaurant has a wonderful breakfast/lunch.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'compound': 0.5719}\n",
            "\n",
            "Sentence:  IT'S REALLY EASY.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.4927}\n",
            "\n",
            "Sentence:  Very good, though!\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.365, 'pos': 0.635, 'compound': 0.54}\n",
            "\n",
            "Sentence:  Not enough volume.\n",
            "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "Sentence:  The cast of veteran actors are more than just a nostalgia trip.  \n",
            "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "Sentence:  Battery is holding up well.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
            "\n",
            "Sentence:  The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.  \n",
            "Sentiment: {'neg': 0.096, 'neu': 0.783, 'pos': 0.122, 'compound': 0.2263}\n",
            "\n",
            "Sentence:  The one big drawback of the MP3 player is that the buttons on the phone's front cover that let you pause and skip songs lock out after a few seconds.\n",
            "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "Sentence:  I guess I liked the details of his dysfunction--he was believable.  \n",
            "Sentiment: {'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.4215}\n",
            "\n",
            "Sentence:  The scenes with the \"oh-so-mature\" neighbour-girl are a misplace.  \n",
            "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "Sentence:  The keyboard is really worthwhile in usefulness and is sturdy enough I don't expect any problems.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.618, 'pos': 0.382, 'compound': 0.7517}\n",
            "\n",
            "Sentence:  I believe the screenwriter did a good job of tying up the loose ends.  \n",
            "Sentiment: {'neg': 0.151, 'neu': 0.658, 'pos': 0.191, 'compound': 0.1531}\n",
            "\n",
            "Sentence:  The shower area is outside so you can only rinse, not take a full shower, unless you don't mind being nude for everyone to see!\n",
            "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "Sentence:  In a word, it is embarrassing.  \n",
            "Sentiment: {'neg': 0.394, 'neu': 0.606, 'pos': 0.0, 'compound': -0.3818}\n",
            "\n",
            "Sentence:  Overall, I like there food and the service.\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'compound': 0.3612}\n",
            "\n",
            "Sentence:  Conclusion - I loved it.  \n",
            "Sentiment: {'neg': 0.0, 'neu': 0.339, 'pos': 0.661, 'compound': 0.5994}\n",
            "\n",
            "Sentence:  the presentation of the food was awful.\n",
            "Sentiment: {'neg': 0.333, 'neu': 0.667, 'pos': 0.0, 'compound': -0.4588}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-NdURzFf10S"
      },
      "source": [
        "**Task 1.2 Classify using transformers Huggingface**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q93xEeklfwT5",
        "outputId": "a352746c-853a-49c8-a942-062396199fa4"
      },
      "source": [
        "!pip install transformers\r\n",
        "from transformers import pipeline"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJszVhR0f00_",
        "outputId": "2508c516-0510-486e-abcb-6a6998e0c956"
      },
      "source": [
        "model = pipeline('sentiment-analysis')\r\n",
        "for sentence in test_set['sentence']:\r\n",
        "    sentiment = model(sentence)\r\n",
        "    print('Sentence: ', sentence)\r\n",
        "    print('Sentiment:', sentiment, end='\\n\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:  This is a really fantastic Thai restaurant which is definitely worth a visit.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9998725056648254}]\n",
            "\n",
            "Sentence:  The RI style calamari was a joke.\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9976921081542969}]\n",
            "\n",
            "Sentence:  Please stay away from the shrimp stir fried noodles.\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9884676337242126}]\n",
            "\n",
            "Sentence:  Anyway, this FS restaurant has a wonderful breakfast/lunch.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9998599886894226}]\n",
            "\n",
            "Sentence:  IT'S REALLY EASY.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9991588592529297}]\n",
            "\n",
            "Sentence:  Very good, though!\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9998641014099121}]\n",
            "\n",
            "Sentence:  Not enough volume.\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9994445443153381}]\n",
            "\n",
            "Sentence:  The cast of veteran actors are more than just a nostalgia trip.  \n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.997856080532074}]\n",
            "\n",
            "Sentence:  Battery is holding up well.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.999653697013855}]\n",
            "\n",
            "Sentence:  The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.  \n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9995948672294617}]\n",
            "\n",
            "Sentence:  The one big drawback of the MP3 player is that the buttons on the phone's front cover that let you pause and skip songs lock out after a few seconds.\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9928373098373413}]\n",
            "\n",
            "Sentence:  I guess I liked the details of his dysfunction--he was believable.  \n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9996277093887329}]\n",
            "\n",
            "Sentence:  The scenes with the \"oh-so-mature\" neighbour-girl are a misplace.  \n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9992032647132874}]\n",
            "\n",
            "Sentence:  The keyboard is really worthwhile in usefulness and is sturdy enough I don't expect any problems.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9997847676277161}]\n",
            "\n",
            "Sentence:  I believe the screenwriter did a good job of tying up the loose ends.  \n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9960194230079651}]\n",
            "\n",
            "Sentence:  The shower area is outside so you can only rinse, not take a full shower, unless you don't mind being nude for everyone to see!\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9695091843605042}]\n",
            "\n",
            "Sentence:  In a word, it is embarrassing.  \n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9995638728141785}]\n",
            "\n",
            "Sentence:  Overall, I like there food and the service.\n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9998387694358826}]\n",
            "\n",
            "Sentence:  Conclusion - I loved it.  \n",
            "Sentiment: [{'label': 'POSITIVE', 'score': 0.9998868703842163}]\n",
            "\n",
            "Sentence:  the presentation of the food was awful.\n",
            "Sentiment: [{'label': 'NEGATIVE', 'score': 0.9997785687446594}]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD32P3jDhMxg"
      },
      "source": [
        "**1.3: Sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "BhAMvnlYhQ4w",
        "outputId": "05729078-a2e5-4830-b4cf-6dc6197fb0bc"
      },
      "source": [
        "import io\r\n",
        "import requests\r\n",
        "url=\"https://raw.githubusercontent.com/kolaveridi/kaggle-Twitter-US-Airline-Sentiment-/master/Tweets.csv\"\r\n",
        "s=requests.get(url).content\r\n",
        "df=pd.read_csv(io.StringIO(s.decode('utf-8')))\r\n",
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flGKsWekkRHk"
      },
      "source": [
        "** Important:: We need to ignore all the features except text since we only have the sentence in the testing phase **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "6_hDPR_rka1f",
        "outputId": "e7d85849-8794-4ee5-e9a5-bbb12c37037b"
      },
      "source": [
        "data = df[['airline_sentiment', 'text']]\r\n",
        "data.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0           neutral                @VirginAmerica What @dhepburn said.\n",
              "1          positive  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  @VirginAmerica and it's a really big bad thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_IJD_C1lNQU"
      },
      "source": [
        "** Time for training and Cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHFQ_obYm6u7"
      },
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "import re\r\n",
        "import operator\r\n",
        "import numpy as np\r\n",
        "import itertools\r\n",
        "\r\n",
        "\r\n",
        "## sklearn\r\n",
        "from sklearn.ensemble import RandomForestClassifier as rf\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier as gb\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "## NLTK\r\n",
        "import nltk\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3c9Pm7stLU"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df63UpLNnCzS"
      },
      "source": [
        "def getWordsFromText(text):\r\n",
        "    ## we will remove numbers, punctuation here\r\n",
        "\r\n",
        "    content = {}\r\n",
        "    \r\n",
        "    stemmer = PorterStemmer()\r\n",
        "\r\n",
        "    text = re.sub('[^A-Za-z ]+', '', text)\r\n",
        "    for item in text.split():\r\n",
        "        ### stemming here\r\n",
        "        stemmed_item = stemmer.stem(item)\r\n",
        "        if stemmed_item not in content:\r\n",
        "            content[stemmed_item] = 1\r\n",
        "        else:\r\n",
        "            content[stemmed_item] += 1\r\n",
        "    return content"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9QeY9K6qku8",
        "outputId": "e9f0238c-038a-4fb6-eb88-087540e02747"
      },
      "source": [
        "getWordsFromText(data['text'][0])\r\n",
        "for content in data['text']:\r\n",
        "  print(content)\r\n",
        "  break"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@VirginAmerica What @dhepburn said.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spl1lZEnnPS0"
      },
      "source": [
        "def createVocabManually(data):\r\n",
        "    \r\n",
        "    K = 600  ### we will choose K topmost words for dictionary\r\n",
        "    \r\n",
        "    ### step 1: remove stopwords\r\n",
        "    ### step 2: stemming\r\n",
        "    \r\n",
        "    nltk.download('stopwords')\r\n",
        "    stop_words = set(stopwords.words('english')) \r\n",
        "    filtered_words = {}\r\n",
        "    \r\n",
        "    for tweet in data['text']:\r\n",
        "        content = getWordsFromText(tweet)\r\n",
        "        for (word, count) in content.items():\r\n",
        "            if word not in filtered_words and word not in stop_words:\r\n",
        "                filtered_words[word] = count\r\n",
        "            elif word not in stop_words:\r\n",
        "                filtered_words[word] += count \r\n",
        "\r\n",
        "\r\n",
        "    sorted_words = sorted(filtered_words.items(), key=operator.itemgetter(1), reverse=True)    \r\n",
        "    \r\n",
        "    ## step 3: vectorize\r\n",
        "    vocab = {sorted_words[i][0]: i for i in range(min(K, len(sorted_words)))}\r\n",
        "    \r\n",
        "    return vocab"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMBLd12sDa3"
      },
      "source": [
        "createVocabManually(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9jX0m9XnW5l"
      },
      "source": [
        "def transfer(text, vocabulary):\r\n",
        "    BOWDj = np.zeros(len(vocabulary))\r\n",
        "    \r\n",
        "    stemmer = PorterStemmer()\r\n",
        "\r\n",
        "    for item in text.split():\r\n",
        "        word = stemmer.stem(item)\r\n",
        "        if word in vocabulary:\r\n",
        "            BOWDj[vocabulary[word]] += 1\r\n",
        "        #else:\r\n",
        "        #    BOWDj[vocabulary['UNK']] += 1\r\n",
        "            \r\n",
        "    return BOWDj"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz1ZTyxvpajT"
      },
      "source": [
        "transfer(data['text'][0], createVocabManually(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxyCKx43oPWh"
      },
      "source": [
        "# 80% in training remaining 20% in validation\r\n",
        "\r\n",
        "\r\n",
        "def loadData(data, dictionary):\r\n",
        "    msk = np.random.rand(len(df)) < 0.8\r\n",
        "\r\n",
        "    data_train = data[msk]\r\n",
        "    data_val = data[~msk]\r\n",
        "\r\n",
        "    Xtrain = []\r\n",
        "    ytrain = []\r\n",
        "\r\n",
        "    for index, row in data_train.iterrows():\r\n",
        "        text = row['text']\r\n",
        "        y = row['airline_sentiment']\r\n",
        "        bow = transfer(text, dictionary)\r\n",
        "        Xtrain.append(bow)\r\n",
        "        ytrain.append(y)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "    Xval = []\r\n",
        "    yval = []\r\n",
        "    for index, row in data_val.iterrows():\r\n",
        "        text = row['text']\r\n",
        "        y = row['airline_sentiment']\r\n",
        "        bow = transfer(text, dictionary)\r\n",
        "        Xval.append(bow)\r\n",
        "        yval.append(y)\r\n",
        "     \r\n",
        "    \r\n",
        "    Xtrain = np.array(Xtrain)\r\n",
        "    ytrain = np.array(ytrain)\r\n",
        "    Xval = np.array(Xval)\r\n",
        "    yval = np.array(yval)\r\n",
        "    return Xtrain, Xval, ytrain, yval"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pikF0ji1uaj0",
        "outputId": "b279a64f-5806-4bf6-bc01-40139b5bc00a"
      },
      "source": [
        "loadData(data, dictionary)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [2., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 2., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), array(['neutral', 'neutral', 'negative', ..., 'positive', 'negative',\n",
              "        'neutral'], dtype='<U8'), array(['positive', 'positive', 'positive', ..., 'negative', 'negative',\n",
              "        'neutral'], dtype='<U8'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFInyWBRni_0",
        "outputId": "bede2cd5-11c4-49df-d8a0-b412d3ed6c73"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    dictionary = createVocabManually(data)\r\n",
        "    Xtrain, Xval, ytrain, yval = loadData(data = data , dictionary = dictionary)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLsILIPjyH34"
      },
      "source": [
        "**Here I need to cross-validate using different hyperparams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3vOB8pynkll",
        "outputId": "9a0fd91f-a3d2-458d-ec86-4094b4086596"
      },
      "source": [
        "## random forest\r\n",
        "model_rf = rf(n_estimators=500)\r\n",
        "\r\n",
        "model_rf.fit(Xtrain, ytrain)\r\n",
        "\r\n",
        "ypred = model_rf.predict(Xval)\r\n",
        "\r\n",
        "print('acc rf:', metrics.accuracy_score(yval, ypred))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc rf: 0.7201077803974402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUDUbIAKx2-e",
        "outputId": "9b564de7-ea9c-4867-afcd-c5bc32c1bf97"
      },
      "source": [
        "## gradient boosting\r\n",
        "model_gb = gb(n_estimators=500)\r\n",
        "\r\n",
        "model_gb.fit(Xtrain, ytrain)\r\n",
        "\r\n",
        "ypred = model_rf.predict(Xval)\r\n",
        "\r\n",
        "print('acc gb:', metrics.accuracy_score(yval, ypred))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc rf: 0.7166167166167167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8UvM0kpyjmg"
      },
      "source": [
        "**Finally we test here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtO7LREWyi58",
        "outputId": "53be9282-b286-4b80-bee8-c29b1c4f84d8"
      },
      "source": [
        "\r\n",
        "for sentence in test_set['sentence']:\r\n",
        "    bow = transfer(sentence, dictionary)\r\n",
        "    sentiment = model_rf.predict([bow])\r\n",
        "\r\n",
        "    print('Sentence: ', sentence)\r\n",
        "    print('Sentiment:', sentiment, end='\\n\\n')\r\n",
        "    \r\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:  This is a really fantastic Thai restaurant which is definitely worth a visit.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  The RI style calamari was a joke.\n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  Please stay away from the shrimp stir fried noodles.\n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  Anyway, this FS restaurant has a wonderful breakfast/lunch.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  IT'S REALLY EASY.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  Very good, though!\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  Not enough volume.\n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  The cast of veteran actors are more than just a nostalgia trip.  \n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  Battery is holding up well.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.  \n",
            "Sentiment: ['positive']\n",
            "\n",
            "Sentence:  The one big drawback of the MP3 player is that the buttons on the phone's front cover that let you pause and skip songs lock out after a few seconds.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  I guess I liked the details of his dysfunction--he was believable.  \n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  The scenes with the \"oh-so-mature\" neighbour-girl are a misplace.  \n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  The keyboard is really worthwhile in usefulness and is sturdy enough I don't expect any problems.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  I believe the screenwriter did a good job of tying up the loose ends.  \n",
            "Sentiment: ['positive']\n",
            "\n",
            "Sentence:  The shower area is outside so you can only rinse, not take a full shower, unless you don't mind being nude for everyone to see!\n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  In a word, it is embarrassing.  \n",
            "Sentiment: ['neutral']\n",
            "\n",
            "Sentence:  Overall, I like there food and the service.\n",
            "Sentiment: ['negative']\n",
            "\n",
            "Sentence:  Conclusion - I loved it.  \n",
            "Sentiment: ['positive']\n",
            "\n",
            "Sentence:  the presentation of the food was awful.\n",
            "Sentiment: ['neutral']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofxqRZREyF9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}